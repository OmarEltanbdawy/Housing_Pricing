{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # removes warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "target = train[train.columns.to_list()[-1]]\n",
    "test_target = pd.read_csv(\"sample_submission.csv\")\n",
    "test_target.drop(\"Id\",axis=1,inplace=True)\n",
    "\n",
    "train.drop(train.columns.to_list()[-1],axis=1,inplace=True)\n",
    "train_id = train['Id']\n",
    "test_id = test['Id']\n",
    "train.drop(\"Id\",axis=1,inplace=True)\n",
    "test.drop(\"Id\",axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 35., 248., 459., 513., 140.,  43.,  14.,   2.,   2.,   3.]),\n",
       " array([135751.31889282, 150340.58461521, 164929.85033761, 179519.11606001,\n",
       "        194108.3817824 , 208697.6475048 , 223286.9132272 , 237876.1789496 ,\n",
       "        252465.44467199, 267054.71039439, 281643.97611679]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig , ax  = plt.subplots(1,2)\n",
    "\n",
    "ax[0].hist(target)\n",
    "ax[1].hist(test_target) #  looks very diffrent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>179183.918243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16518.303051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>135751.318893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>168703.011202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>179208.665698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>186789.409363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>281643.976117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SalePrice\n",
       "count    1459.000000\n",
       "mean   179183.918243\n",
       "std     16518.303051\n",
       "min    135751.318893\n",
       "25%    168703.011202\n",
       "50%    179208.665698\n",
       "75%    186789.409363\n",
       "max    281643.976117"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.describe() # very diffrent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(target)\n",
    "test_target = np.log1p(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 18.,  92., 259., 501., 402., 134.,  37.,   9.,   4.,   3.]),\n",
       " array([11.81858732, 11.89156885, 11.96455038, 12.03753191, 12.11051343,\n",
       "        12.18349496, 12.25647649, 12.32945802, 12.40243955, 12.47542108,\n",
       "        12.54840261]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig , ax  = plt.subplots(1,2)\n",
    "\n",
    "ax[0].hist(target)\n",
    "ax[1].hist(test_target) #  much better  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'MSZoning',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinType2',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'KitchenQual',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Functional',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    259\n",
       "MasVnrArea       8\n",
       "GarageYrBlt     81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()[train.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    227\n",
       "MasVnrArea      15\n",
       "GarageYrBlt     78\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()[train.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['GarageYrBlt'].fillna(combined['YearBuilt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    486\n",
       "MasVnrArea      23\n",
       "GarageYrBlt      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isna().sum()[train.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    " \n",
    "mean_imputer=SimpleImputer()\n",
    "mean_imputer.fit(train)\n",
    "\n",
    "combined = pd.DataFrame(mean_imputer.transform(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "col_num_h = combined.describe().T[combined.describe().T['max'] > 300].index.to_list()\n",
    "col_num_m = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold', 'RemodAfterBuilt']\n",
    "col_num_l = combined.describe().T[combined.describe().T['max'] <= 15].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mean       std  min  max\n",
      "112  0.503940  0.500070  0.0  1.0\n",
      "227  0.511134  0.499962  0.0  1.0\n",
      "212  0.511477  0.499954  0.0  1.0\n",
      "178  0.448099  0.497384  0.0  1.0\n",
      "185  0.439534  0.496415  0.0  1.0\n",
      "..        ...       ...  ...  ...\n",
      "139  0.000685  0.018506  0.0  1.0\n",
      "272  0.000685  0.018506  0.0  1.0\n",
      "128  0.000685  0.018506  0.0  1.0\n",
      "126  0.000685  0.018506  0.0  1.0\n",
      "103  0.000685  0.018506  0.0  1.0\n",
      "\n",
      "[288 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Min-max scale col_num_m and col_num_l\n",
    "scaler = MinMaxScaler()\n",
    "combined= pd.DataFrame(scaler.fit_transform(combined))\n",
    "print(combined.describe().T[['mean', 'std', 'min', 'max']].sort_values(by='std', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isna().sum()[combined.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all bool to float, True to 1, False to 0\n",
    "combined = combined.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = combined.iloc[-len(test_id):, :]\n",
    "train = combined.iloc[:-len(test_id), :]\n",
    "train[target] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(target, axis=1)\n",
    "y = target\n",
    "\n",
    "x_test = test\n",
    "y_test = test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.247699\n",
       "1       12.109016\n",
       "2       12.317171\n",
       "3       11.849405\n",
       "4       12.429220\n",
       "          ...    \n",
       "1455    12.072547\n",
       "1456    12.254868\n",
       "1457    12.493133\n",
       "1458    11.864469\n",
       "1459    11.901590\n",
       "Name: SalePrice, Length: 1460, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=[X.shape[1]]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=128, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber = keras.losses.Huber(delta=0.05)\n",
    "model.compile(loss=huber, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "10/10 [==============================] - 2s 58ms/step - loss: 0.5952 - val_loss: 0.5923\n",
      "Epoch 2/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5862 - val_loss: 0.5872\n",
      "Epoch 3/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5760 - val_loss: 0.5829\n",
      "Epoch 4/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5634 - val_loss: 0.5781\n",
      "Epoch 5/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5510 - val_loss: 0.5723\n",
      "Epoch 6/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5358 - val_loss: 0.5648\n",
      "Epoch 7/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5151 - val_loss: 0.5530\n",
      "Epoch 8/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4940 - val_loss: 0.5401\n",
      "Epoch 9/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4698 - val_loss: 0.5242\n",
      "Epoch 10/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4409 - val_loss: 0.4903\n",
      "Epoch 11/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4057 - val_loss: 0.4438\n",
      "Epoch 12/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3674 - val_loss: 0.3898\n",
      "Epoch 13/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3251 - val_loss: 0.2971\n",
      "Epoch 14/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2734 - val_loss: 0.2094\n",
      "Epoch 15/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2206 - val_loss: 0.1476\n",
      "Epoch 16/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1825 - val_loss: 0.1118\n",
      "Epoch 17/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1503 - val_loss: 0.1408\n",
      "Epoch 18/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1315 - val_loss: 0.0595\n",
      "Epoch 19/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1241 - val_loss: 0.0415\n",
      "Epoch 20/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1220 - val_loss: 0.0458\n",
      "Epoch 21/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1232 - val_loss: 0.0386\n",
      "Epoch 22/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1179 - val_loss: 0.0492\n",
      "Epoch 23/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1116 - val_loss: 0.0376\n",
      "Epoch 24/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.1056 - val_loss: 0.0364\n",
      "Epoch 25/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1025 - val_loss: 0.0479\n",
      "Epoch 26/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1016 - val_loss: 0.0349\n",
      "Epoch 27/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0983 - val_loss: 0.0546\n",
      "Epoch 28/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0983 - val_loss: 0.0444\n",
      "Epoch 29/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0972 - val_loss: 0.0380\n",
      "Epoch 30/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0937 - val_loss: 0.0414\n",
      "Epoch 31/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0932 - val_loss: 0.0319\n",
      "Epoch 32/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0926 - val_loss: 0.0303\n",
      "Epoch 33/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0906 - val_loss: 0.0419\n",
      "Epoch 34/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0855 - val_loss: 0.0317\n",
      "Epoch 35/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0811 - val_loss: 0.0432\n",
      "Epoch 36/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0891 - val_loss: 0.0262\n",
      "Epoch 37/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0828 - val_loss: 0.0283\n",
      "Epoch 38/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0818 - val_loss: 0.0282\n",
      "Epoch 39/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0805 - val_loss: 0.0351\n",
      "Epoch 40/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0752 - val_loss: 0.0342\n",
      "Epoch 41/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0777 - val_loss: 0.0376\n",
      "Epoch 42/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0761 - val_loss: 0.0290\n",
      "Epoch 43/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0752 - val_loss: 0.0343\n",
      "Epoch 44/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0724 - val_loss: 0.0221\n",
      "Epoch 45/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0722 - val_loss: 0.0200\n",
      "Epoch 46/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0699 - val_loss: 0.0220\n",
      "Epoch 47/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0669 - val_loss: 0.0320\n",
      "Epoch 48/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0659 - val_loss: 0.0251\n",
      "Epoch 49/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0683 - val_loss: 0.0307\n",
      "Epoch 50/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0683 - val_loss: 0.0338\n",
      "Epoch 51/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0674 - val_loss: 0.0301\n",
      "Epoch 52/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0640 - val_loss: 0.0210\n",
      "Epoch 53/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0631 - val_loss: 0.0211\n",
      "Epoch 54/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0615 - val_loss: 0.0256\n",
      "Epoch 55/4000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0637 - val_loss: 0.0194\n",
      "Epoch 56/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0621 - val_loss: 0.0178\n",
      "Epoch 57/4000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0601 - val_loss: 0.0162\n",
      "Epoch 58/4000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0584 - val_loss: 0.0207\n",
      "Epoch 59/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0586 - val_loss: 0.0209\n",
      "Epoch 60/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0585 - val_loss: 0.0197\n",
      "Epoch 61/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0578 - val_loss: 0.0153\n",
      "Epoch 62/4000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0569 - val_loss: 0.0171\n",
      "Epoch 63/4000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0517 - val_loss: 0.0194\n",
      "Epoch 64/4000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0557 - val_loss: 0.0139\n",
      "Epoch 65/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0532 - val_loss: 0.0130\n",
      "Epoch 66/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0521 - val_loss: 0.0183\n",
      "Epoch 67/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0552 - val_loss: 0.0178\n",
      "Epoch 68/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0531 - val_loss: 0.0126\n",
      "Epoch 69/4000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0515 - val_loss: 0.0145\n",
      "Epoch 70/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0520 - val_loss: 0.0142\n",
      "Epoch 71/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0498 - val_loss: 0.0172\n",
      "Epoch 72/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0493 - val_loss: 0.0182\n",
      "Epoch 73/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0479 - val_loss: 0.0210\n",
      "Epoch 74/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0483 - val_loss: 0.0193\n",
      "Epoch 75/4000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0461 - val_loss: 0.0203\n",
      "Epoch 76/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0485 - val_loss: 0.0131\n",
      "Epoch 77/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0488 - val_loss: 0.0140\n",
      "Epoch 78/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0444 - val_loss: 0.0145\n",
      "Epoch 79/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0445 - val_loss: 0.0148\n",
      "Epoch 80/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0437 - val_loss: 0.0122\n",
      "Epoch 81/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0444 - val_loss: 0.0132\n",
      "Epoch 82/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0447 - val_loss: 0.0156\n",
      "Epoch 83/4000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0441 - val_loss: 0.0127\n",
      "Epoch 84/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0423 - val_loss: 0.0173\n",
      "Epoch 85/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0422 - val_loss: 0.0136\n",
      "Epoch 86/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0421 - val_loss: 0.0099\n",
      "Epoch 87/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0408 - val_loss: 0.0105\n",
      "Epoch 88/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0420 - val_loss: 0.0153\n",
      "Epoch 89/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0410 - val_loss: 0.0092\n",
      "Epoch 90/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0402 - val_loss: 0.0116\n",
      "Epoch 91/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0390 - val_loss: 0.0115\n",
      "Epoch 92/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0378 - val_loss: 0.0140\n",
      "Epoch 93/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0386 - val_loss: 0.0113\n",
      "Epoch 94/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0376 - val_loss: 0.0088\n",
      "Epoch 95/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0409 - val_loss: 0.0124\n",
      "Epoch 96/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0385 - val_loss: 0.0147\n",
      "Epoch 97/4000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0387 - val_loss: 0.0127\n",
      "Epoch 98/4000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0387 - val_loss: 0.0099\n",
      "Epoch 99/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0369 - val_loss: 0.0092\n",
      "Epoch 100/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0358 - val_loss: 0.0112\n",
      "Epoch 101/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0382 - val_loss: 0.0092\n",
      "Epoch 102/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0357 - val_loss: 0.0090\n",
      "Epoch 103/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0368 - val_loss: 0.0083\n",
      "Epoch 104/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0352 - val_loss: 0.0097\n",
      "Epoch 105/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0377 - val_loss: 0.0120\n",
      "Epoch 106/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0362 - val_loss: 0.0081\n",
      "Epoch 107/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0378 - val_loss: 0.0101\n",
      "Epoch 108/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0353 - val_loss: 0.0105\n",
      "Epoch 109/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0366 - val_loss: 0.0098\n",
      "Epoch 110/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0356 - val_loss: 0.0144\n",
      "Epoch 111/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0362 - val_loss: 0.0118\n",
      "Epoch 112/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0346 - val_loss: 0.0117\n",
      "Epoch 113/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0365 - val_loss: 0.0086\n",
      "Epoch 114/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0337 - val_loss: 0.0087\n",
      "Epoch 115/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0335 - val_loss: 0.0106\n",
      "Epoch 116/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0345 - val_loss: 0.0076\n",
      "Epoch 117/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0371 - val_loss: 0.0084\n",
      "Epoch 118/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0339 - val_loss: 0.0105\n",
      "Epoch 119/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0344 - val_loss: 0.0093\n",
      "Epoch 120/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0337 - val_loss: 0.0110\n",
      "Epoch 121/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0331 - val_loss: 0.0106\n",
      "Epoch 122/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0100\n",
      "Epoch 123/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0342 - val_loss: 0.0095\n",
      "Epoch 124/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0352 - val_loss: 0.0079\n",
      "Epoch 125/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0330 - val_loss: 0.0074\n",
      "Epoch 126/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0324 - val_loss: 0.0085\n",
      "Epoch 127/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0077\n",
      "Epoch 128/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0075\n",
      "Epoch 129/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0076\n",
      "Epoch 130/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0324 - val_loss: 0.0077\n",
      "Epoch 131/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0298 - val_loss: 0.0073\n",
      "Epoch 132/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0325 - val_loss: 0.0070\n",
      "Epoch 133/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.0072\n",
      "Epoch 134/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0070\n",
      "Epoch 135/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0310 - val_loss: 0.0130\n",
      "Epoch 136/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0310 - val_loss: 0.0093\n",
      "Epoch 137/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0102\n",
      "Epoch 138/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0306 - val_loss: 0.0094\n",
      "Epoch 139/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0319 - val_loss: 0.0098\n",
      "Epoch 140/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0313 - val_loss: 0.0079\n",
      "Epoch 141/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0331 - val_loss: 0.0075\n",
      "Epoch 142/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0081\n",
      "Epoch 143/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0309 - val_loss: 0.0083\n",
      "Epoch 144/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0304 - val_loss: 0.0069\n",
      "Epoch 145/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0291 - val_loss: 0.0104\n",
      "Epoch 146/4000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0335 - val_loss: 0.0075\n",
      "Epoch 147/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0294 - val_loss: 0.0075\n",
      "Epoch 148/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0325 - val_loss: 0.0074\n",
      "Epoch 149/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0278 - val_loss: 0.0077\n",
      "Epoch 150/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0075\n",
      "Epoch 151/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0306 - val_loss: 0.0074\n",
      "Epoch 152/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0286 - val_loss: 0.0085\n",
      "Epoch 153/4000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0316 - val_loss: 0.0079\n",
      "Epoch 154/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0288 - val_loss: 0.0073\n",
      "Epoch 155/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0305 - val_loss: 0.0088\n",
      "Epoch 156/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0294 - val_loss: 0.0085\n",
      "Epoch 157/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0316 - val_loss: 0.0083\n",
      "Epoch 158/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0294 - val_loss: 0.0090\n",
      "Epoch 159/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0296 - val_loss: 0.0079\n",
      "Epoch 160/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0301 - val_loss: 0.0088\n",
      "Epoch 161/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0085\n",
      "Epoch 162/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0272 - val_loss: 0.0070\n",
      "Epoch 163/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0291 - val_loss: 0.0081\n",
      "Epoch 164/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0301 - val_loss: 0.0072\n",
      "Epoch 165/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0285 - val_loss: 0.0073\n",
      "Epoch 166/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0286 - val_loss: 0.0086\n",
      "Epoch 167/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0290 - val_loss: 0.0078\n",
      "Epoch 168/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0287 - val_loss: 0.0076\n",
      "Epoch 169/4000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0281 - val_loss: 0.0094\n",
      "Epoch 170/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0295 - val_loss: 0.0089\n",
      "Epoch 171/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0294 - val_loss: 0.0079\n",
      "Epoch 172/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0279 - val_loss: 0.0082\n",
      "Epoch 173/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0279 - val_loss: 0.0095\n",
      "Epoch 174/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0096\n",
      "Epoch 175/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0292 - val_loss: 0.0068\n",
      "Epoch 176/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0277 - val_loss: 0.0088\n",
      "Epoch 177/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0263 - val_loss: 0.0073\n",
      "Epoch 178/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0285 - val_loss: 0.0081\n",
      "Epoch 179/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0292 - val_loss: 0.0066\n",
      "Epoch 180/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0286 - val_loss: 0.0063\n",
      "Epoch 181/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.0069\n",
      "Epoch 182/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0287 - val_loss: 0.0061\n",
      "Epoch 183/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0286 - val_loss: 0.0056\n",
      "Epoch 184/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0086\n",
      "Epoch 185/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0279 - val_loss: 0.0058\n",
      "Epoch 186/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0292 - val_loss: 0.0066\n",
      "Epoch 187/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0288 - val_loss: 0.0068\n",
      "Epoch 188/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0066\n",
      "Epoch 189/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0281 - val_loss: 0.0078\n",
      "Epoch 190/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0280 - val_loss: 0.0063\n",
      "Epoch 191/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0273 - val_loss: 0.0069\n",
      "Epoch 192/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0271 - val_loss: 0.0077\n",
      "Epoch 193/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0275 - val_loss: 0.0071\n",
      "Epoch 194/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0072\n",
      "Epoch 195/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0266 - val_loss: 0.0066\n",
      "Epoch 196/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0077\n",
      "Epoch 197/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0289 - val_loss: 0.0060\n",
      "Epoch 198/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0084\n",
      "Epoch 199/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0287 - val_loss: 0.0079\n",
      "Epoch 200/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0060\n",
      "Epoch 201/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0078\n",
      "Epoch 202/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0281 - val_loss: 0.0063\n",
      "Epoch 203/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0262 - val_loss: 0.0076\n",
      "Epoch 204/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0267 - val_loss: 0.0063\n",
      "Epoch 205/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0281 - val_loss: 0.0074\n",
      "Epoch 206/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0062\n",
      "Epoch 207/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0260 - val_loss: 0.0069\n",
      "Epoch 208/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.0074\n",
      "Epoch 209/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0065\n",
      "Epoch 210/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0271 - val_loss: 0.0079\n",
      "Epoch 211/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0057\n",
      "Epoch 212/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0269 - val_loss: 0.0081\n",
      "Epoch 213/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0061\n",
      "Epoch 214/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 0.0076\n",
      "Epoch 215/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0074\n",
      "Epoch 216/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0274 - val_loss: 0.0057\n",
      "Epoch 217/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0079\n",
      "Epoch 218/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0240 - val_loss: 0.0056\n",
      "Epoch 219/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0275 - val_loss: 0.0062\n",
      "Epoch 220/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0280 - val_loss: 0.0058\n",
      "Epoch 221/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0266 - val_loss: 0.0053\n",
      "Epoch 222/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0263 - val_loss: 0.0070\n",
      "Epoch 223/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0269 - val_loss: 0.0057\n",
      "Epoch 224/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0253 - val_loss: 0.0059\n",
      "Epoch 225/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0052\n",
      "Epoch 226/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0256 - val_loss: 0.0057\n",
      "Epoch 227/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0058\n",
      "Epoch 228/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0276 - val_loss: 0.0058\n",
      "Epoch 229/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0268 - val_loss: 0.0058\n",
      "Epoch 230/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0260 - val_loss: 0.0056\n",
      "Epoch 231/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0253 - val_loss: 0.0073\n",
      "Epoch 232/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0273 - val_loss: 0.0060\n",
      "Epoch 233/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0074\n",
      "Epoch 234/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0065\n",
      "Epoch 235/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0076\n",
      "Epoch 236/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0052\n",
      "Epoch 237/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0061\n",
      "Epoch 238/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0251 - val_loss: 0.0066\n",
      "Epoch 239/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0058\n",
      "Epoch 240/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0256 - val_loss: 0.0083\n",
      "Epoch 241/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0267 - val_loss: 0.0051\n",
      "Epoch 242/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.0055\n",
      "Epoch 243/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0062\n",
      "Epoch 244/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0084\n",
      "Epoch 245/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0260 - val_loss: 0.0059\n",
      "Epoch 246/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0068\n",
      "Epoch 247/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0056\n",
      "Epoch 248/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0241 - val_loss: 0.0049\n",
      "Epoch 249/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0052\n",
      "Epoch 250/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0051\n",
      "Epoch 251/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0260 - val_loss: 0.0055\n",
      "Epoch 252/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.0059\n",
      "Epoch 253/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 0.0054\n",
      "Epoch 254/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0061\n",
      "Epoch 255/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0254 - val_loss: 0.0062\n",
      "Epoch 256/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0255 - val_loss: 0.0061\n",
      "Epoch 257/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0263 - val_loss: 0.0052\n",
      "Epoch 258/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0253 - val_loss: 0.0060\n",
      "Epoch 259/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0057\n",
      "Epoch 260/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0249 - val_loss: 0.0059\n",
      "Epoch 261/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0242 - val_loss: 0.0054\n",
      "Epoch 262/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0267 - val_loss: 0.0064\n",
      "Epoch 263/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0048\n",
      "Epoch 264/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0058\n",
      "Epoch 265/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0055\n",
      "Epoch 266/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0073\n",
      "Epoch 267/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0065\n",
      "Epoch 268/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0066\n",
      "Epoch 269/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0050\n",
      "Epoch 270/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 0.0047\n",
      "Epoch 271/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0080\n",
      "Epoch 272/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0074\n",
      "Epoch 273/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0247 - val_loss: 0.0057\n",
      "Epoch 274/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0234 - val_loss: 0.0057\n",
      "Epoch 275/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0061\n",
      "Epoch 276/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0242 - val_loss: 0.0062\n",
      "Epoch 277/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0247 - val_loss: 0.0063\n",
      "Epoch 278/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0063\n",
      "Epoch 279/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 0.0072\n",
      "Epoch 280/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0056\n",
      "Epoch 281/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0079\n",
      "Epoch 282/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0056\n",
      "Epoch 283/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0064\n",
      "Epoch 284/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0053\n",
      "Epoch 285/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0248 - val_loss: 0.0051\n",
      "Epoch 286/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0068\n",
      "Epoch 287/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0053\n",
      "Epoch 288/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0054\n",
      "Epoch 289/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0054\n",
      "Epoch 290/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0071\n",
      "Epoch 291/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0053\n",
      "Epoch 292/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0046\n",
      "Epoch 293/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0234 - val_loss: 0.0056\n",
      "Epoch 294/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0053\n",
      "Epoch 295/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0047\n",
      "Epoch 296/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0048\n",
      "Epoch 297/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0226 - val_loss: 0.0064\n",
      "Epoch 298/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0240 - val_loss: 0.0049\n",
      "Epoch 299/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0058\n",
      "Epoch 300/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0053\n",
      "Epoch 301/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0261 - val_loss: 0.0072\n",
      "Epoch 302/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0049\n",
      "Epoch 303/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0243 - val_loss: 0.0056\n",
      "Epoch 304/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0045\n",
      "Epoch 305/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0052\n",
      "Epoch 306/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0062\n",
      "Epoch 307/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0045\n",
      "Epoch 308/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0214 - val_loss: 0.0053\n",
      "Epoch 309/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0049\n",
      "Epoch 310/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0057\n",
      "Epoch 311/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0053\n",
      "Epoch 312/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0050\n",
      "Epoch 313/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0049\n",
      "Epoch 314/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0050\n",
      "Epoch 315/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0236 - val_loss: 0.0067\n",
      "Epoch 316/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0052\n",
      "Epoch 317/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0064\n",
      "Epoch 318/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0049\n",
      "Epoch 319/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 0.0055\n",
      "Epoch 320/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0062\n",
      "Epoch 321/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0242 - val_loss: 0.0058\n",
      "Epoch 322/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0059\n",
      "Epoch 323/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0051\n",
      "Epoch 324/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0051\n",
      "Epoch 325/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0056\n",
      "Epoch 326/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0057\n",
      "Epoch 327/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0243 - val_loss: 0.0050\n",
      "Epoch 328/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0224 - val_loss: 0.0060\n",
      "Epoch 329/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0059\n",
      "Epoch 330/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0056\n",
      "Epoch 331/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0235 - val_loss: 0.0055\n",
      "Epoch 332/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0245 - val_loss: 0.0054\n",
      "Epoch 333/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0046\n",
      "Epoch 334/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0243 - val_loss: 0.0052\n",
      "Epoch 335/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 0.0044\n",
      "Epoch 336/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0048\n",
      "Epoch 337/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0050\n",
      "Epoch 338/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0048\n",
      "Epoch 339/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0234 - val_loss: 0.0055\n",
      "Epoch 340/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0231 - val_loss: 0.0052\n",
      "Epoch 341/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0050\n",
      "Epoch 342/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0241 - val_loss: 0.0057\n",
      "Epoch 343/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0046\n",
      "Epoch 344/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0053\n",
      "Epoch 345/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.0047\n",
      "Epoch 346/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0046\n",
      "Epoch 347/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0224 - val_loss: 0.0041\n",
      "Epoch 348/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0046\n",
      "Epoch 349/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0218 - val_loss: 0.0051\n",
      "Epoch 350/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0047\n",
      "Epoch 351/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0065\n",
      "Epoch 352/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0044\n",
      "Epoch 353/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0063\n",
      "Epoch 354/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0058\n",
      "Epoch 355/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0242 - val_loss: 0.0057\n",
      "Epoch 356/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0247 - val_loss: 0.0051\n",
      "Epoch 357/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.0048\n",
      "Epoch 358/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0046\n",
      "Epoch 359/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0045\n",
      "Epoch 360/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0044\n",
      "Epoch 361/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0042\n",
      "Epoch 362/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0044\n",
      "Epoch 363/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0047\n",
      "Epoch 364/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0051\n",
      "Epoch 365/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0049\n",
      "Epoch 366/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 0.0040\n",
      "Epoch 367/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0043\n",
      "Epoch 368/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0043\n",
      "Epoch 369/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0046\n",
      "Epoch 370/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0044\n",
      "Epoch 371/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0047\n",
      "Epoch 372/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0048\n",
      "Epoch 373/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0041\n",
      "Epoch 374/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0045\n",
      "Epoch 375/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0044\n",
      "Epoch 376/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0043\n",
      "Epoch 377/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0041\n",
      "Epoch 378/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0040\n",
      "Epoch 379/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0224 - val_loss: 0.0041\n",
      "Epoch 380/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0044\n",
      "Epoch 381/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0063\n",
      "Epoch 382/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0046\n",
      "Epoch 383/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0049\n",
      "Epoch 384/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0076\n",
      "Epoch 385/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0043\n",
      "Epoch 386/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0042\n",
      "Epoch 387/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0043\n",
      "Epoch 388/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0045\n",
      "Epoch 389/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0223 - val_loss: 0.0050\n",
      "Epoch 390/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0224 - val_loss: 0.0064\n",
      "Epoch 391/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0234 - val_loss: 0.0056\n",
      "Epoch 392/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0233 - val_loss: 0.0051\n",
      "Epoch 393/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0232 - val_loss: 0.0041\n",
      "Epoch 394/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0219 - val_loss: 0.0048\n",
      "Epoch 395/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0227 - val_loss: 0.0056\n",
      "Epoch 396/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0230 - val_loss: 0.0047\n",
      "Epoch 397/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0228 - val_loss: 0.0042\n",
      "Epoch 398/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0042\n",
      "Epoch 399/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0213 - val_loss: 0.0044\n",
      "Epoch 400/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.0055\n",
      "Epoch 401/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0220 - val_loss: 0.0055\n",
      "Epoch 402/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0229 - val_loss: 0.0053\n",
      "Epoch 403/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0230 - val_loss: 0.0046\n",
      "Epoch 404/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0046\n",
      "Epoch 405/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0238 - val_loss: 0.0042\n",
      "Epoch 406/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0212 - val_loss: 0.0042\n",
      "Epoch 407/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0235 - val_loss: 0.0040\n",
      "Epoch 408/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0215 - val_loss: 0.0038\n",
      "Epoch 409/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0049\n",
      "Epoch 410/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0041\n",
      "Epoch 411/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.0050\n",
      "Epoch 412/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.0041\n",
      "Epoch 413/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0047\n",
      "Epoch 414/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0051\n",
      "Epoch 415/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0231 - val_loss: 0.0052\n",
      "Epoch 416/4000\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0213 - val_loss: 0.0047\n",
      "Epoch 417/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0221 - val_loss: 0.0043\n",
      "Epoch 418/4000\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.0218 - val_loss: 0.0057\n",
      "Epoch 419/4000\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 0.0230 - val_loss: 0.0047\n",
      "Epoch 420/4000\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.0203 - val_loss: 0.0067\n",
      "Epoch 421/4000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.0210 - val_loss: 0.0043\n",
      "Epoch 422/4000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0217 - val_loss: 0.0044\n",
      "Epoch 423/4000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0227 - val_loss: 0.0045\n",
      "Epoch 424/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0215 - val_loss: 0.0070\n",
      "Epoch 425/4000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0221 - val_loss: 0.0048\n",
      "Epoch 426/4000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0217 - val_loss: 0.0049\n",
      "Epoch 427/4000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0206 - val_loss: 0.0044\n",
      "Epoch 428/4000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0210 - val_loss: 0.0043\n",
      "Epoch 429/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0237 - val_loss: 0.0042\n",
      "Epoch 430/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0060\n",
      "Epoch 431/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0218 - val_loss: 0.0042\n",
      "Epoch 432/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0218 - val_loss: 0.0041\n",
      "Epoch 433/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0224 - val_loss: 0.0042\n",
      "Epoch 434/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.0046\n",
      "Epoch 435/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0213 - val_loss: 0.0048\n",
      "Epoch 436/4000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0221 - val_loss: 0.0042\n",
      "Epoch 437/4000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0215 - val_loss: 0.0046\n",
      "Epoch 438/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0214 - val_loss: 0.0044\n",
      "Epoch 439/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0229 - val_loss: 0.0045\n",
      "Epoch 440/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.0066\n",
      "Epoch 441/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0217 - val_loss: 0.0056\n",
      "Epoch 442/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0217 - val_loss: 0.0071\n",
      "Epoch 443/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0041\n",
      "Epoch 444/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0042\n",
      "Epoch 445/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0041\n",
      "Epoch 446/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0045\n",
      "Epoch 447/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0058\n",
      "Epoch 448/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0052\n",
      "Epoch 449/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0217 - val_loss: 0.0050\n",
      "Epoch 450/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0052\n",
      "Epoch 451/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0213 - val_loss: 0.0045\n",
      "Epoch 452/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0216 - val_loss: 0.0047\n",
      "Epoch 453/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0055\n",
      "Epoch 454/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0046\n",
      "Epoch 455/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0046\n",
      "Epoch 456/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0047\n",
      "Epoch 457/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.0044\n",
      "Epoch 458/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0045\n",
      "Epoch 459/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0204 - val_loss: 0.0049\n",
      "Epoch 460/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0048\n",
      "Epoch 461/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0041\n",
      "Epoch 462/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0042\n",
      "Epoch 463/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0059\n",
      "Epoch 464/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0202 - val_loss: 0.0038\n",
      "Epoch 465/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0053\n",
      "Epoch 466/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0046\n",
      "Epoch 467/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0050\n",
      "Epoch 468/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0050\n",
      "Epoch 469/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0216 - val_loss: 0.0058\n",
      "Epoch 470/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0042\n",
      "Epoch 471/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0060\n",
      "Epoch 472/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 0.0044\n",
      "Epoch 473/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 0.0057\n",
      "Epoch 474/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0042\n",
      "Epoch 475/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0059\n",
      "Epoch 476/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0049\n",
      "Epoch 477/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0054\n",
      "Epoch 478/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0052\n",
      "Epoch 479/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0046\n",
      "Epoch 480/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0209 - val_loss: 0.0052\n",
      "Epoch 481/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0221 - val_loss: 0.0045\n",
      "Epoch 482/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0041\n",
      "Epoch 483/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0046\n",
      "Epoch 484/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0042\n",
      "Epoch 485/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0052\n",
      "Epoch 486/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0040\n",
      "Epoch 487/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0047\n",
      "Epoch 488/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0046\n",
      "Epoch 489/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0048\n",
      "Epoch 490/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0206 - val_loss: 0.0047\n",
      "Epoch 491/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0064\n",
      "Epoch 492/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0204 - val_loss: 0.0064\n",
      "Epoch 493/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0047\n",
      "Epoch 494/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0045\n",
      "Epoch 495/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0225 - val_loss: 0.0059\n",
      "Epoch 496/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0047\n",
      "Epoch 497/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0051\n",
      "Epoch 498/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0217 - val_loss: 0.0049\n",
      "Epoch 499/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0215 - val_loss: 0.0045\n",
      "Epoch 500/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0051\n",
      "Epoch 501/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0049\n",
      "Epoch 502/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0206 - val_loss: 0.0057\n",
      "Epoch 503/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0041\n",
      "Epoch 504/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0061\n",
      "Epoch 505/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0044\n",
      "Epoch 506/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0211 - val_loss: 0.0064\n",
      "Epoch 507/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0045\n",
      "Epoch 508/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0048\n",
      "Epoch 509/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0201 - val_loss: 0.0042\n",
      "Epoch 510/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0044\n",
      "Epoch 511/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0045\n",
      "Epoch 512/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0042\n",
      "Epoch 513/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.0047\n",
      "Epoch 514/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0045\n",
      "Epoch 515/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0046\n",
      "Epoch 516/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0046\n",
      "Epoch 517/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0045\n",
      "Epoch 518/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0048\n",
      "Epoch 519/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0214 - val_loss: 0.0054\n",
      "Epoch 520/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0204 - val_loss: 0.0040\n",
      "Epoch 521/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0042\n",
      "Epoch 522/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0201 - val_loss: 0.0038\n",
      "Epoch 523/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0210 - val_loss: 0.0042\n",
      "Epoch 524/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0039\n",
      "Epoch 525/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 0.0038\n",
      "Epoch 526/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0043\n",
      "Epoch 527/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0208 - val_loss: 0.0038\n",
      "Epoch 528/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0049\n",
      "Epoch 529/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0045\n",
      "Epoch 530/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0041\n",
      "Epoch 531/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0214 - val_loss: 0.0046\n",
      "Epoch 532/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0204 - val_loss: 0.0061\n",
      "Epoch 533/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0045\n",
      "Epoch 534/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0056\n",
      "Epoch 535/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0040\n",
      "Epoch 536/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0211 - val_loss: 0.0045\n",
      "Epoch 537/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0046\n",
      "Epoch 538/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0049\n",
      "Epoch 539/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0047\n",
      "Epoch 540/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0041\n",
      "Epoch 541/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0056\n",
      "Epoch 542/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0046\n",
      "Epoch 543/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0050\n",
      "Epoch 544/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0038\n",
      "Epoch 545/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0041\n",
      "Epoch 546/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0047\n",
      "Epoch 547/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0049\n",
      "Epoch 548/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0048\n",
      "Epoch 549/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0048\n",
      "Epoch 550/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0049\n",
      "Epoch 551/4000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0054\n",
      "Epoch 552/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0060\n",
      "Epoch 553/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0048\n",
      "Epoch 554/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0210 - val_loss: 0.0040\n",
      "Epoch 555/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0187 - val_loss: 0.0055\n",
      "Epoch 556/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0041\n",
      "Epoch 557/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0224 - val_loss: 0.0051\n",
      "Epoch 558/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0210 - val_loss: 0.0054\n",
      "Epoch 559/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0206 - val_loss: 0.0071\n",
      "Epoch 560/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0208 - val_loss: 0.0041\n",
      "Epoch 561/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0059\n",
      "Epoch 562/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 0.0045\n",
      "Epoch 563/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0054\n",
      "Epoch 564/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0197 - val_loss: 0.0053\n",
      "Epoch 565/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0205 - val_loss: 0.0039\n",
      "Epoch 566/4000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0204 - val_loss: 0.0048\n",
      "Epoch 567/4000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0199 - val_loss: 0.0047\n",
      "Epoch 568/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0199 - val_loss: 0.0049\n",
      "Epoch 569/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0039\n",
      "Epoch 570/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0198 - val_loss: 0.0043\n",
      "Epoch 571/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0196 - val_loss: 0.0042\n",
      "Epoch 572/4000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0192 - val_loss: 0.0042\n",
      "Epoch 573/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0041\n",
      "Epoch 574/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0055\n",
      "Epoch 575/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0036\n",
      "Epoch 576/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0053\n",
      "Epoch 577/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0041\n",
      "Epoch 578/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0051\n",
      "Epoch 579/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0041\n",
      "Epoch 580/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0050\n",
      "Epoch 581/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0045\n",
      "Epoch 582/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0212 - val_loss: 0.0054\n",
      "Epoch 583/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0042\n",
      "Epoch 584/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0053\n",
      "Epoch 585/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0039\n",
      "Epoch 586/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0042\n",
      "Epoch 587/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0051\n",
      "Epoch 588/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0050\n",
      "Epoch 589/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0045\n",
      "Epoch 590/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0200 - val_loss: 0.0040\n",
      "Epoch 591/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0039\n",
      "Epoch 592/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0038\n",
      "Epoch 593/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0040\n",
      "Epoch 594/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0039\n",
      "Epoch 595/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0042\n",
      "Epoch 596/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0199 - val_loss: 0.0058\n",
      "Epoch 597/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0208 - val_loss: 0.0055\n",
      "Epoch 598/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0198 - val_loss: 0.0090\n",
      "Epoch 599/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0063\n",
      "Epoch 600/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0076\n",
      "Epoch 601/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0045\n",
      "Epoch 602/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0066\n",
      "Epoch 603/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0200 - val_loss: 0.0043\n",
      "Epoch 604/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0042\n",
      "Epoch 605/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0068\n",
      "Epoch 606/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0042\n",
      "Epoch 607/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0048\n",
      "Epoch 608/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0042\n",
      "Epoch 609/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0045\n",
      "Epoch 610/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0061\n",
      "Epoch 611/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0045\n",
      "Epoch 612/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0217 - val_loss: 0.0048\n",
      "Epoch 613/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0056\n",
      "Epoch 614/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0044\n",
      "Epoch 615/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0051\n",
      "Epoch 616/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0199 - val_loss: 0.0043\n",
      "Epoch 617/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0053\n",
      "Epoch 618/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0047\n",
      "Epoch 619/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0046\n",
      "Epoch 620/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0042\n",
      "Epoch 621/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0040\n",
      "Epoch 622/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0050\n",
      "Epoch 623/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0042\n",
      "Epoch 624/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0047\n",
      "Epoch 625/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0037\n",
      "Epoch 626/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0041\n",
      "Epoch 627/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0049\n",
      "Epoch 628/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0062\n",
      "Epoch 629/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 630/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0214 - val_loss: 0.0097\n",
      "Epoch 631/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0204 - val_loss: 0.0110\n",
      "Epoch 632/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0048\n",
      "Epoch 633/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0040\n",
      "Epoch 634/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0040\n",
      "Epoch 635/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0040\n",
      "Epoch 636/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0207 - val_loss: 0.0055\n",
      "Epoch 637/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0052\n",
      "Epoch 638/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0044\n",
      "Epoch 639/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0205 - val_loss: 0.0037\n",
      "Epoch 640/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0063\n",
      "Epoch 641/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0038\n",
      "Epoch 642/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0197 - val_loss: 0.0046\n",
      "Epoch 643/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0038\n",
      "Epoch 644/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0046\n",
      "Epoch 645/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0043\n",
      "Epoch 646/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0049\n",
      "Epoch 647/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0203 - val_loss: 0.0053\n",
      "Epoch 648/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0190 - val_loss: 0.0039\n",
      "Epoch 649/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0044\n",
      "Epoch 650/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0196 - val_loss: 0.0043\n",
      "Epoch 651/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0193 - val_loss: 0.0039\n",
      "Epoch 652/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0040\n",
      "Epoch 653/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0040\n",
      "Epoch 654/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0045\n",
      "Epoch 655/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0039\n",
      "Epoch 656/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0197 - val_loss: 0.0040\n",
      "Epoch 657/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0052\n",
      "Epoch 658/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0058\n",
      "Epoch 659/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0049\n",
      "Epoch 660/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0207 - val_loss: 0.0041\n",
      "Epoch 661/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0040\n",
      "Epoch 662/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0040\n",
      "Epoch 663/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0061\n",
      "Epoch 664/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0063\n",
      "Epoch 665/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0196 - val_loss: 0.0042\n",
      "Epoch 666/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0194 - val_loss: 0.0048\n",
      "Epoch 667/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0053\n",
      "Epoch 668/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.0042\n",
      "Epoch 669/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0190 - val_loss: 0.0043\n",
      "Epoch 670/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0043\n",
      "Epoch 671/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0195 - val_loss: 0.0042\n",
      "Epoch 672/4000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0183 - val_loss: 0.0042\n",
      "Epoch 673/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0197 - val_loss: 0.0044\n",
      "Epoch 674/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0053\n",
      "Epoch 675/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0202 - val_loss: 0.0041\n",
      "Epoch 676/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0203 - val_loss: 0.0060\n",
      "Epoch 677/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0050\n",
      "Epoch 678/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0051\n",
      "Epoch 679/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0197 - val_loss: 0.0039\n",
      "Epoch 680/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0040\n",
      "Epoch 681/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0038\n",
      "Epoch 682/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0040\n",
      "Epoch 683/4000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0049\n",
      "Epoch 684/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0041\n",
      "Epoch 685/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0041\n",
      "Epoch 686/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0050\n",
      "Epoch 687/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0045\n",
      "Epoch 688/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0042\n",
      "Epoch 689/4000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0042\n",
      "Epoch 690/4000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0188 - val_loss: 0.0051\n",
      "Epoch 691/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0188 - val_loss: 0.0044\n",
      "Epoch 692/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0188 - val_loss: 0.0043\n",
      "Epoch 693/4000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 0.0056\n",
      "Epoch 694/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0183 - val_loss: 0.0039\n",
      "Epoch 695/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0064\n",
      "Epoch 696/4000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0199 - val_loss: 0.0047\n",
      "Epoch 697/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0046\n",
      "Epoch 698/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0049\n",
      "Epoch 699/4000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0043\n",
      "Epoch 700/4000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.0043\n",
      "Epoch 701/4000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0054\n",
      "Epoch 702/4000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0040\n",
      "Epoch 703/4000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y,\n",
    "                    batch_size=128,\n",
    "                    epochs=4000,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 3ms/step\n",
      "RMSE on the training set: 0.1731860516742884\n"
     ]
    }
   ],
   "source": [
    "# Calculate the RMSE on the training set\n",
    "y_pred = model.predict(X)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE on the training set:', np.sqrt(mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(test)\n",
    "y_pred = np.expm1(y_pred)\n",
    "y_pred = pd.DataFrame(y_pred, index=test_id, columns=[\"SalePrice\"])\n",
    "y_pred.to_csv('submission_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\":[0.01,0.02,0.03],\n",
    "    \"max_depth\":[2,4,6,8,10],\n",
    "    \"n_estimators\":[100,200,300,400,500,600,700,800,1000],\n",
    "}\n",
    "\n",
    "grid_dt = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=params,\n",
    "    scoring=mean_squared_error,\n",
    "    cv=10,\n",
    "    n_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None,\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=&lt;function mean_squared_error at 0x000002232AA0C040&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None,\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=&lt;function mean_squared_error at 0x000002232AA0C040&gt;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None,\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.02, 0.03],\n",
       "                                        'max_depth': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=<function mean_squared_error at 0x000002232AA0C040>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=500, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = grid_dt.best_estimator_\n",
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=6,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=5000,\n",
       "             n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "             random_state=27, reg_alpha=0.005, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=6,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=5000,\n",
       "             n_jobs=4, nthread=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "             random_state=27, reg_alpha=0.005, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=6,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=5000,\n",
       "             n_jobs=4, nthread=4, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=27, reg_alpha=0.005, ...)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb4 = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "xgb4.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training set: 0.026312782677150193\n"
     ]
    }
   ],
   "source": [
    "# Calculate the RMSE on the training set\n",
    "y_pred = xgb4.predict(X)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE on the training set:', np.sqrt(mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = xgb4.predict(test)\n",
    "y_pred = np.expm1(y_pred)\n",
    "y_pred = pd.DataFrame(y_pred, index=test_id, columns=[\"SalePrice\"])\n",
    "y_pred.to_csv('submission_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
